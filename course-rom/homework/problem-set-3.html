<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Problem Set 3: A Posteriori Error Bounds, Greedy Sampling Procedure :: Course Rom</title>
    <link rel="canonical" href="https://feelpp.github.io/course-rom/course-rom/homework/problem-set-3.html">
    <meta name="generator" content="Antora 3.1.4">
    <link rel="stylesheet" href="../../_/css/site.css">
<link rel="icon" href="../../_/img/favicon.ico" type="image/x-icon">
<script>!function(l,p){if(l.protocol!==p&&l.host=="docs.antora.org"){l.protocol=p}else if(/\.gitlab\.io$/.test(l.host)){l.replace(p+"//docs.antora.org"+l.pathname.substr(l.pathname.indexOf("/",1))+l.search+l.hash)}}(location,"https:")</script>

<script src="../../_/js/vendor/tabs-block-extension.js"></script>
<script src="../../_/js/vendor/tabs-block-behavior.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/plotly.js-dist-min@2" charset="utf-8"></script>
  <script src="https://cdn.jsdelivr.net/npm/d3@7" charset="utf-8"></script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },

  TeX: {
      Macros: {
      bold: ["{\\bf #1}",1],
      calTh: "{\\mathcal{T}_h}",
      card: ["{\\operatorname{card}(#1)}",1],
      card: ["{\\operatorname{card}(#1)}",1],
      Ck: ["{\\mathcal{C}^{#1}}",1],
      deformt: ["{\\mathbf{\\varepsilon(#1)}}",1],
      diam: "{\\operatorname{diam}}",
      dim: ["{\\operatorname{dim}(#1)}",1],
      disp: ["{\\mathbf{#1}}",1],
      domain: "{\\Omega}",
      ds: "",
      essinf: "{\\operatorname{ess}\\, \\operatorname{inf}}",
      F:"{\\mathcal{F}}",
      geo: "{\\mathrm{geo}}",
      Ich: ["{\\mathcal{I}^{#1}_{c,h}#2}",2],
      Id: "{\\mathcal{I}}",
      Ilag: ["{\\mathcal{I}^{\\mathrm{lag}}_{#1}}",1],
      jump: ["{[\\![ #1 ]\\!]}",1],
      n:"{\\mathbf{n}}",
      Ne: "{N_{\\mathrm{e}}}",
      Next: "{\\mathrm{n}}",
      nf: "{n_f}",
      ngeo: "{n_{\\mathrm{geo}}}",
      Nma: "{N_{\\mathrm{ma}}}",
      NN: "{\\mathbb N}",
      Nno: "{N_{\\mathrm{no}}}",
      Nso: "{N_{\\mathrm{so}}}",
      opdim: "{\\operatorname{dim}}",
      p: "{\\mathrm{p}}",
      P:"{\\mathcal{P}}",
      Pch: ["{P^{#1}_{c,h}}",1],
      Pcho: ["{P^{#1}_{c,h,0}}",1],
      Pk: ["{\\mathcal{P}^{#1}}",1],
      poly: ["{\\mathbb{#1}",1],
      poly: ["{\\mathbb{#1}}",1],
      prect: ["{\\left\\(#1\\right\\)}",1],
      q:"{\\mathbf{q}}",
      Qch: ["{Q^{#1}_{c,h}}",1],
      Qk: ["{\\mathcal{Q}^{#1}}",1],
      R: ["{\\mathbb{R}^{#1}}",1],
      RR: "{\\mathbb R}",
      set: ["{\\left\\{#1\\right\\}}",1],
      stresst: ["{\\mathbf{\\sigma(#1)}}",1],
      T:"{\\mathcal{T}}",
      tr: "{\\operatorname{tr}}",
      v:"{\\mathbf{v}}",
      vertiii: ["\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert",1]
  },
  extensions: ["mhchem.js"] 
  }
});
</script>
<!--<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"></script>-->
<!-- <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_CHTML'></script>
<!--<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>-->

<!--<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" integrity="sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js" integrity="sha384-jmxIlussZWB7qCuB+PgKG1uLjjxbVVIayPJwi6cG6Zb4YKq0JIw+OMnkkEC7kYCq" crossorigin="anonymous"></script>-->
<script>var uiRootPath = '../../_'</script>

  </head>
  <body class="article">
<header class="header">
    <nav class="navbar navbar-expand-sm bg-dark navbar-dark navbar-template-project" style="border-top: 4px solid #9E9E9E">
        <div class="navbar-brand">
            <div class="navbar-item feelpp-logo">
                <a href="https://feelpp.github.io/course-rom">Course Rom</a>
            </div>
            <button class="navbar-burger" data-target="topbar-nav">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>

        <div id="topbar-nav" class="navbar-menu">
            <div class="navbar-end">
                <div class="navbar-item">
                    <a href="https://docs.feelpp.org/">Documentation Reference</a>
                </div>
                <div class="navbar-item has-dropdown is-hoverable download-item">
                    <div class="navbar-item"><a href="https://docs.feelpp.org/user/latest/install/index.html" class="download-btn">Get Feel++</a></div>
                </div>
                <div class="navbar-item">
                    <a class="navbar-brand"  href="https://www.cemosis.fr">
                        <img class="cemosis-logo"  src="../../_/img/cemosis-logo.svg" alt="Cemosis logo"/>
                    </a>
                </div>
            </div>
        </div>
    </nav>
</header>
<div class="body">
<a href="#" class="menu-expand-toggle"></a>
<div class="nav-container" data-component="course-rom" data-version="">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Template Project</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../quickstart.html">Quickstart</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../overview.html">Overview</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Homework</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="problem-set-1.html">Homework 1</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="problem-set-2.html">Homework 2</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="problem-set-3.html">Homework 3</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Setting up the development Environment</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../env/cmake.html">CMake Environment</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../env/antora.html">Antora Environment</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../env/vscode.html">VS Code Integration</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../env/githubactions.html">GitHub Actions</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../env/rename.html">Renaming the Project</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../env/jupyter.html">Jupyter Notebook</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Template Project</span>
    <span class="version"></span>
  </div>
  <ul class="components">
      <li class="component is-current">
        <a class="title" href="../index.html">Template Project</a>
      </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
  <button class="nav-toggle"></button>
    <a href="../index.html" class="home-link"></a>
  <nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Template Project</a></li>
    <li>Homework</li>
    <li><a href="problem-set-3.html">Homework 3</a></li>
  </ul>
</nav>

  
    <div class="edit-this-page"><a href="https://github.com/feelpp/course-rom/edit/master/docs/modules/ROOT/pages/homework/problem-set-3.adoc">Edit this Page</a></div>
  
  <div class="page-downloads">
  <span class="label">Download as</span>
  <ul class="download-options">
    <li>
      <a onclick="print(this)" href="#" data-toggle="tooltip" data-placement="left" title="Print to PDF"
         class="pdf-download">
        <img class="pdf-file-icon icon" src="../../_/img/pdf.svg"/> .pdf
      </a>
    </li>
      <li>
        <a href="../_attachments/homework/problem-set-3.ipynb"
           title="Download Jupyter Notebook" data-toggle="tooltip" data-placement="left" class="jupyter-download">
          <img class="jupyter-file-icon icon" src="../../_/img/jupyter-logo.svg"/> .ipynb
        </a>
      </li>
  </ul>
</div>
</div>

  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Problem Set 3: A Posteriori Error Bounds, Greedy Sampling Procedure</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>We consider again the problem of designing a thermal fin of Problem Set 1 and 2. Given the reduced basis approximation implemented in PS2, we turn to implementing the associated a posteriori error estimation procedures developed in the lecture. The second half of this problem set is devoted to implementing the greedy sampling procedure. We will consider the following two cases:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Case I (\(P=1\)): We keep the Biot number fixed at \(Bi = 0.1\) and assume that the conductivities of all fins are equivalent, i.e., \(k = k_1 = k_2 = k_3 = k_4\), but are allowed to vary between 0.1 and 10 — we thus have \(\mu \in D = [0.1, 10\).] For this \(P = 1\) case we define the \(X\)-inner product \((\cdot, \cdot)_X = a(\cdot, \cdot; \bar{\mu}),\) where \(\bar{\mu} = 1.\)</p>
</li>
<li>
<p>Case II (\(P = 2\)): We again assume that the conductivities of all fins are equivalent, i.e., \(k = k_1 = k_2 = k_3 = k_4\) , but are allowed to vary between 0.1 and 10; furthermore, we assume that the Biot number satisfies \(0.01 \leq Bi \leq 1.\) We thus have \(\mu = (k, Bi) = [0.1, 10] \times [0.01, 1].\) For this \(P = 2\) case we define the \(X\)-inner product \((\cdot, \cdot)_X = a(\cdot, \cdot; \bar{\mu}),\) where \(\bar{\mu} = (1, 0.1)\) (the two inner products are in fact the same since \(Bi = 0.1\) here).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>We also define the parameter grids \(G^{\mathrm{lin}}_{[ \mu_{min} , \mu_{max} ;10]}\) and \(G^{\mathrm{ln}}_{[ \mu_{min} , \mu_{max} ;10]}\). The former grid is equi-spaced in \(\mu\), the latter grid is equi-spaced in \(ln(\mu)\) — often advantageous within the reduced basis context. More generally, the &#8220;log&#8221; spacing represents equal relative increments, and thus represents better coverage for parameters that vary over a large range. For the \(P = 2\) case we can then define tensor grids over \(\mathcal{D}\), \(\Xi^{\mathrm{log}}_M  \subset D  \subset \mathbb{R}^2\) , as</p>
</div>
<div class="stemblock">
<div class="content">
\[\Xi^{log}_M = G^{log}_{[ \mu_{min} , \mu_{max} ;M ]} \times G^{log}_{[ \mu_{min} , \mu_{max} ;M ]} ;\]
</div>
</div>
<div class="paragraph">
<p>note \(\Xi^{log}_M\) contains \(M^2\) points; a similar definition applies to \(\Xi^{lin}_M\). We also define a particular test grid (biased neither towards &#8220;log&#8221; nor &#8220;lin&#8221;)</p>
</div>
<div class="stemblock">
<div class="content">
\[\Xi^{test}_M =  \Xi^{lin}_M \cup \Xi^{log}_M ;\]
</div>
</div>
<div class="paragraph">
<p>note \(\Xi^{test}_M\) contains \(2M^2\) points.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sec:1"><a class="anchor" href="#sec:1"></a>1. Part 1 - Coercivity Lower Bound and X-Norm Error Bound</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We first consider the construction of the lower bound for the coercivity constant.</p>
</div>
<div class="sect2">
<h3 id="_q1"><a class="anchor" href="#_q1"></a>1.1. Q1.</h3>
<div class="paragraph">
<p>Since our problem is parametrically coercive, the simple \(\min \theta\)-approach suffices for the construction of the coercivity lower bound, \(\alpha_{LB} (\mu)\). However, we have to slightly adapt the lower bound to Case I and II.</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Derive an explicit expression for \(\alpha_{LB} (\mu)\) for Case I and Case II.</p>
</li>
<li>
<p>What is the largest effectivity for the energy norm error bound and the output error bound we should anticipate for Case I and Case II?</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_q2"><a class="anchor" href="#_q2"></a>1.2. Q2.</h3>
<div class="paragraph">
<p>Prove the bounding properties of the \(X\)-norm error bound, i.e., the effectivity \(\eta_N(\mu)\) satisfies</p>
</div>
<div class="stemblock">
<div class="content">
\[1 \leq \eta_N(\mu) \leq \frac{\gamma_{UB} (\mu)}{\alpha_{LB} (\mu)}, \quad \forall \mu \in \mathcal{D}.\]
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_part_2_a_posteriori_error_estimation"><a class="anchor" href="#_part_2_a_posteriori_error_estimation"></a>2. Part 2 - A Posteriori Error Estimation</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Given the coercivity lower bound, we can now turn to implementing the a posteriori error bounds. Note that, in principle, there is an online-inefficient and an online-efficient way to evaluate these error bounds. We first consider the latter: From the lecture we know that the energy norm a posteriori error bound is given by</p>
</div>
<div id="eq:2" class="stemblock 1">
<div class="content">
\[\Delta^{en}_N(\mu)= \frac{\|\hat{e}(\mu\|}{\sqrt{\alpha_{LB}(\mu)}}\]
</div>
</div>
<div class="paragraph">
<p>where \(\hat{e}(\mu) \in X\) satisfies</p>
</div>
<div id="eq:2" class="stemblock 2">
<div class="content">
\[(\hat{e}(\mu), v)_X = r(v; \mu), \quad \forall v \in X,\]
</div>
</div>
<div class="paragraph">
<p>and the residual is given by</p>
</div>
<div id="eq:2" class="stemblock 3">
<div class="content">
\[r(v; \mu) = f (v; \mu) - a(u_N (\mu), v; \mu),\quad \forall v \in X.\]
</div>
</div>
<div class="paragraph">
<p>For any new \(\mu\) and associated reduced basis solution, \(u_N (\mu),\) we can now directly calculate \(\hat{e}(\mu)\) from <a href="#eq:2.2">2.2</a> and <a href="#eq:2.3">2.3</a>, evaluate the norm \(\|\hat{e}(\mu)||_X\) and — given \(\alpha_{LB} (\mu)\) — obtain \(\Delta^{en}_N (\mu)\) from <a href="#eq:2.1">2.1</a>. Although this approach is online-inefficient because the computational cost depends on \(O(\mathcal{N})\), it is nevertheless useful as a means to test your offline-online computational decomposition. We will consider Case I and Case II in the sequel. Note that you should only require one  code to handle both cases, i.e., Case I is a specialization of Case II by keeping one of the parameters fixed. Also, when using  you should try to replace loops by matrix-vector products as much as possible (e.g. try to write the nested loop over \(N\) when summing up the contributions of the \(\|\hat{e}(\mu)\|_X\) norm as a vector-matrix-vector product — the nested loop over \(Q_a\) is less critical).</p>
</div>
<div class="sect2">
<h3 id="_q3"><a class="anchor" href="#_q3"></a>2.1. Q3.</h3>
<div class="paragraph">
<p>We first consider Case I. To answer this question you should use the sample set \(S_N\) provided for PS2 (<code>RB_sample.sample1</code>), orthonormalize the basis functions, and use the medium grid.</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Implement an offline/online version of the a posteriori error bound calculation following the computational decomposition shown in the lecture. Show that the direct calculation and the offline-online decomposition deliver the same results for the error bound, \(\Delta^{en}_N (\mu)\), for all \(N (1 \leq N \leq 8)\) and (say) \(5\) parameter values randomly distributed in \(\mathcal{D}.\)</p>
</li>
<li>
<p>Calculate \(\eta^{en}_{\min,N},\eta^{en}_{\max,N}\) and \(\eta^{en}_{ave,N}\) the minimum, maximum, and average effectivity \(\eta^{en}_N(\mu)\) over \(\Xi test = G^{lin}[ \mu_{min} , \mu_{max} ;50\) \cup G^{ln}[ \mu_{min} , \mu_{max} ;50\]], respectively (note that \(\Xi^{test}\) is of size 100 since \(P = 1\)).</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Present the results in a table for all \(N\) . Is the minimum effectivity greater than unity? How does the maximum effectivity compare with your theoretical upper bound for the effectivity? (Note you should exclude from the min/max/mean-operation all points in \(\Xi^{test}\) for which \(\|u(\mu) - u_N (\mu)\|_X\) is less than (say) \(10e-11\) .)</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Evalulate the effectivity for \(\mu = 1\) for \(N = 1,\ldots, 8\). What do you observe? Justify your answer. (d ) Evaluate the exact error, \(\|u(\mu) - u_N (\mu)\|_X\) , and error bound for \(\mu = 0.1\). What do you observe? Justify your answer.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_q4"><a class="anchor" href="#_q4"></a>2.2. Q4.</h3>
<div class="paragraph">
<p>We consider Case II. To answer this question you should use the sample set \(S_N\) provided for the PS2 (<code>RB_sample.sample3</code>), orthonormalize the basis functions, and use the medium grid.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Implement an offline/online version of the a posteriori error bound calculation following the computational decomposition shown in the lecture. Show that the direct calculation and the offline-online decomposition deliver the same results for the error bound, \(\Delta^{en}_N (\mu)\), for all \(N\) \((1 \leq N \leq 46)\) and (say) 5 parameter values randomly distributed in \(\mathcal{D}\).</p>
</li>
<li>
<p>Calculate \(\eta^{en}_{\min,N},\eta^{en}_{\max,N}\) and \(\eta^{en}_{ave,N}\) the minimum, maximum, and average effectivity \(\eta^{en}_N(\mu)\) over \(\Xi^{test}_M = \Xi^{lin}_{M=10}\cup \Xi^{log}_{M=10}\), respectively. Present the results in a table for \(N = 5, 10, 20,30, 40.\) Is the minimum effectivity greater than unity? How does the maximum effectivity compare with your theoretical upper bound for the effectivity? (Note you should again exclude from the min/max/mean-operation all points in \(\Xi^{test}_M\) for which \(\|u(\mu) - u_N (\mu)\|_X\) is less than (say) \(10e-11\).)</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_part_3_reduced_basis_output_bound"><a class="anchor" href="#_part_3_reduced_basis_output_bound"></a>3. Part 3 - Reduced Basis Output Bound</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Given the a posteriori error bound from Part 2 we can now directly evaluate the output error bound.</p>
</div>
<div class="sect2">
<h3 id="_q5"><a class="anchor" href="#_q5"></a>3.1. Q5.</h3>
<div class="paragraph">
<p>We consider Case II. To answer this question you should use the sample set SN provided for PS2 (<code>RB_sample.sample3</code>), orthnormalize the basis functions, and use the medium grid.</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Extend your  code to also calculate the output error bound.</p>
</li>
<li>
<p>Calculate \(\eta^{s}_{\min,N},\eta^{s}_{\max,N}\) and \(\eta^{s}_{ave,N}\) the minimum, maximum, and average effectivity \(\eta^{s}_N(\mu)\) over \(\Xi^{test}_M =  \Xi^{lin}_M =10 \cup  \Xi^{log}_M =10\), respectively. Present the results in a table for \(N = 5, 10, 20,30, 40.\) How does the maximum effectivity compare with your theoretical upper bound for the effectivity? (Note you should exclude from the min/max/mean-operation all points in \(\Xi^{test}\) for which \(|s(\mu) - s_N (\mu)|\) is less than (say) \(10e-11\) .)</p>
</li>
<li>
<p>What value of \(N\) do you require to achieve a relative accuracy in the output bound of approximately 1%? What is the true error for this value of \(N\) ?</p>
</li>
<li>
<p>How does the online computational cost to calculate \(\Delta^s_N (\mu)\) compare to the online computational cost to calculate \(s_N (\mu)\) as a function of \(N\) (take the average over the test sample \(\Xi^{test}_M\) )?</p>
</li>
<li>
<p>How does the computational cost to calculate the truth output \(s(\mu)\) compare to the online computational cost to calculate \(s_N (\mu)\) and \(\Delta^s_N (\mu)\) as a function of \(N\) (take the average over the test sample \(\Xi^{test}_M\) )?</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_part_4_greedy_sampling_procedure"><a class="anchor" href="#_part_4_greedy_sampling_procedure"></a>4. Part 4 - Greedy Sampling Procedure</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Given your (now tested and - hopefully - functioning) offline-online computational decomposition for the reduced basis approximation and associated a posteriori error estimation, we turn to the Greedy Sampling Procedure. In PS2 you where given the sample sets \(S_N\) — now you can construct these yourself.</p>
</div>
<div class="paragraph">
<p>For this problem set, you should use the algorithm with \(\omega(\mu) =
|||u_N (\mu)|||_\mu\) (note that we can calculate \(|||u_N (\mu)|||_\mu\) online-efficient in \(O(N^2)\) operations — as opposed to \(|||u(\mu)|||_\mu\) which would require \(O(\mathcal{N})\) operations). We set the desired error tolerance to \(\varepsilon_{tol,\min} =
10e-6\) and choose \(S_1 =  \mu_{min}\) and \(X_1 = \mathrm{span}\{u( \mu_{min} )\}.\)</p>
</div>
<div class="paragraph">
<p>Note that there are many steps implicit in the greedy loop. In particular, after the update \(S_N = S_{N-1} \cup \mu^{*}_N\) , we must calculate \(u(\mu^{*}_N )\) to construct (using Gram-Schmidt) the new contribution to our orthonormal basis set, \(\zeta_N\) , to &#8220;form&#8221; \(X_N\) , and finally calculate all the necessary online quantities for both our reduced basis approximation and associated a posteriori error estimation. We note here a practical point for our hierarchical space: as we proceed from \(N\) to \(N + 1\), we should only compute the necessary incremental quantities — the incremental contributions to the various online inner-product arrays required for the reduced basis approximation and a posteriori error estimators.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_q6"><a class="anchor" href="#_q6"></a>5. Q6.</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We consider Case I. Apply the greedy algorithm with \(\Xi^{train} = G^{ln}_{[ \mu_{min} , \mu_{max} ;100]} , S_1 = \mu_{min} = 0.1\) and \(\varepsilon_{tol,min} = 1e-6\).</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>What is the value of \(N_{max}\) to achieve the desired accuracy? In a sequence of \(N_{max}\) figures (or subplots), plot the relative exact error \(\|u(\mu) - u_N (\mu)\|_X /|||u_N (\mu)|||_\mu\) and the relative energy error bound, \(\Delta^{en}_N (\mu)/|||u_N (\mu)|||_\mu\) , over \(\mu \in  \Xi^{train}\) . In each plot, mark the parameter value which is picked by the greedy procedure in this step.</p>
</li>
<li>
<p>Plot \(\Delta_N^{max}\) as a function of \(N\) .</p>
</li>
<li>
<p>Generate a non-hierarchical reduced basis approximation for \(S^{lin}_N=G^{lin}_{[ \mu_{min} , \mu_{max} ;N ]}\) and \(S^{ln}_N =
G^{ln}_{[ \mu_{min} , \mu_{max} ;N ]}\) with \(2 \leq N \leq N_{max}\) . We would like to compare the convergence of the reduced basis approximation generated using the greedy algorithm and the reduced basis approximations from the linear and logarithmic sample. Plot the convergence of the maximum relative error in the energy norm \(max_{\mu \in \Xi^test} |||u(\mu) - u_N (\mu)|||_\mu /|||u(\mu)|||_\mu\) as a function of \(N\) for all ln three cases in one plot. Here, \(\Xi^{test} = G^{lin}_{[ \mu_{min} , \mu_{max} ;50]} \cup G^{ln}[ \mu_{min} , \mu_{max} ;50]\) is a test sample of size \(n_{test} = 100.\)</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_q7"><a class="anchor" href="#_q7"></a>6. Q7.</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We consider Case II.</p>
</div>
<div class="paragraph">
<p>Apply the greedy algorithm with \(\Xi^{train} =  \Xi^{log}_M\) (the log tensor product grid with \(M = 25\)), \(S_1 = \mu_{min} = (0.1, 0.01)\), and \(\varepsilon_{tol,min} = 10e-6\) .</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>What is the value of \(N_{max}\) to achieve the desired accuracy?</p>
</li>
<li>
<p>Plot \(\Delta_N^{max}\) as a function of \(N\).</p>
</li>
<li>
<p>Plot your greedy samples \(S_N\) ; present your results as dots in the \((ln \mu_1 , ln \mu_2 )\) plane. Can you attribute the observed distribution of parameter points to any mathematical or physical causes?</p>
</li>
<li>
<p>For the reduced basis approximation you just generated, plot the convergence of the maximum relative error in the energy norm \(\max_{\mu \in \Xi^{test}} |||u(\mu) - u_N (\mu)|||_\mu /|||u(\mu)|||_\mu\) and the maximum relative output error \(\max_{\mu\in \Xi^{test}} |{T_{root}} (\mu) - {T_{root}}_N (\mu)|/{T_{root}} (\mu)\) as a function of \(N\) . Use \(\Xi^{test} = \Xi^{test}_M\) with \(M = 10\) (the combined linear and logarithmic tensor product grid).</p>
</li>
</ol>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer" style="border-top: 2px solid #e9e9e9; background-color: #fafafa; padding-bottom: 2em; padding-top: 2em;">
    <div class="container" style="display: flex; flex-direction: column; align-items: center; gap: 0.5em;">
        <div>
            <a href="https://www.cemosis.fr">
                <img src="../../_/img/cemosis-logo.svg" alt="Cemosis logo" height="50">
            </a>
        </div>
        <span style="font-size: 0.8rem; color: #9e9e9e">© 2023 <a href="https://www.cemosis.fr" style="text-decoration: underline;">Cemosis</a>, Université de Strasbourg</span>
    </div>
</footer>
<script id="site-script" src="../../_/js/site.js" data-ui-root-path="../../_"></script>


<script async src="../../_/js/vendor/fontawesome-icon-defs.js"></script>
<script async src="../../_/js/vendor/fontawesome.js"></script>
<script async src="../../_/js/vendor/highlight.js"></script>


<script type="text/javascript">
function toggleFullScreen() {
   var doc = window.document;
   var docEl = doc.documentElement;

   var requestFullScreen = docEl.requestFullscreen || docEl.mozRequestFullScreen || docEl.webkitRequestFullScreen || docEl.msRequestFullscreen;
   var cancelFullScreen = doc.exitFullscreen || doc.mozCancelFullScreen || doc.webkitExitFullscreen || doc.msExitFullscreen;

   if(!doc.fullscreenElement && !doc.mozFullScreenElement && !doc.webkitFullscreenElement && !doc.msFullscreenElement) {
       requestFullScreen.call(docEl);
   }
   else {
       cancelFullScreen.call(doc);
   }
}
</script>
  </body>
</html>
